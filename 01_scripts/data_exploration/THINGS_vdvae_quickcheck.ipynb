{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# THINGS \u00d7 VDVAE \u2013 Quick Data Checks\n",
        "\n",
        "Use this notebook to sanity-check that your **predicted VDVAE latents** and **ref_latents** exist, load correctly, and match expected shapes.\n",
        "\n",
        "## What this checks\n",
        "- Confirms existence of files (predicted latents `.npy`, `ref_latents.npz`).\n",
        "- Prints shapes for both.\n",
        "- Verifies that the **flattened latent dimension** equals the sum of expected per-level sizes (`layer_dims`).\n",
        "- Optionally lists the first/last few entries of your `test_image_paths.txt` to confirm index\u2194image ordering.\n",
        "\n",
        "\ud83d\udca1 **Instructions:**\n",
        "1. Edit the parameters in the first code cell (subject, alpha, base directories) to match your setup.\n",
        "2. Run cells top-to-bottom.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Parameters (EDIT ME) ---\n",
        "SUBJ = 1            # subject number (unpadded)\n",
        "ALPHA = 50000       # ridge alpha used for predictions (e.g., 50000)\n",
        "\n",
        "# Base directories (EDIT if your layout differs)\n",
        "BASE = \"/home/rothermm/THINGS\"\n",
        "PREPROC_DIR = f\"{BASE}/02_data/preprocessed_data/subj{SUBJ:02d}\"\n",
        "PRED_DIR    = f\"{BASE}/02_data/predicted_features/subj{SUBJ:02d}\"\n",
        "FEAT_DIR    = f\"{BASE}/02_data/extracted_features/subj{SUBJ:02d}\"\n",
        "RESULTS_DIR = f\"{BASE}/03_results/vdvae/subj{SUBJ:02d}\"\n",
        "\n",
        "# File names\n",
        "def alpha_tag(a):\n",
        "    return (str(int(a)) if float(a).is_integer() else str(a).replace('.', 'p'))\n",
        "\n",
        "PRED_NPY = f\"{PRED_DIR}/things_vdvae_pred_sub{SUBJ:02d}_31l_alpha{alpha_tag(ALPHA)}.npy\"\n",
        "REF_NPZ  = f\"{FEAT_DIR}/ref_latents.npz\"\n",
        "\n",
        "# Optional: for inspecting image ordering\n",
        "TEST_PATHS_TXT = f\"{PREPROC_DIR}/test_image_paths.txt\"\n",
        "\n",
        "print(\"Using paths:\")\n",
        "print(\"  PRED_NPY:\", PRED_NPY)\n",
        "print(\"  REF_NPZ :\", REF_NPZ)\n",
        "print(\"  TEST_PATHS_TXT:\", TEST_PATHS_TXT)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Existence checks & basic loading ---\n",
        "import os, numpy as np\n",
        "\n",
        "pred_exists = os.path.exists(PRED_NPY)\n",
        "ref_exists  = os.path.exists(REF_NPZ)\n",
        "print(\"pred exists:\", pred_exists)\n",
        "print(\"ref  exists:\", ref_exists)\n",
        "\n",
        "if pred_exists:\n",
        "    pred = np.load(PRED_NPY)\n",
        "    print(\"pred shape:\", pred.shape, \"dtype:\", pred.dtype)\n",
        "else:\n",
        "    pred = None\n",
        "\n",
        "if ref_exists:\n",
        "    ref = np.load(REF_NPZ, allow_pickle=True)[\"ref_latent\"]\n",
        "    print(\"ref levels:\", len(ref))\n",
        "    if len(ref) > 0:\n",
        "        print(\"ref[0]['z'] shape:\", ref[0]['z'].shape)\n",
        "else:\n",
        "    ref = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Verify flattened latent dimension matches per-level sizes ---\n",
        "import numpy as np\n",
        "\n",
        "# Must match your extraction stacking order (31 levels)\n",
        "layer_dims = np.array([\n",
        "    2**4,2**4,2**8,2**8,2**8,\n",
        "    2**8,2**10,2**10,2**10,2**10,2**10,2**10,2**10,\n",
        "    2**10,2**12,2**12,2**12,2**12,2**12,2**12,2**12,\n",
        "    2**12,2**12,2**12,2**12,2**12,2**12,2**12,2**12,\n",
        "    2**12,2**14\n",
        "], dtype=np.int64)\n",
        "\n",
        "if pred is not None:\n",
        "    total = int(layer_dims.sum())\n",
        "    print(\"Sum(layer_dims)   =\", total)\n",
        "    print(\"pred latent width =\", pred.shape[1])\n",
        "    if pred.shape[1] != total:\n",
        "        print(\"WARNING: width mismatch -> check your layer_dims vs extraction\")\n",
        "    else:\n",
        "        print(\"OK: pred width matches sum(layer_dims)\")\n",
        "\n",
        "    # Show first few split offsets\n",
        "    offs = np.cumsum(np.r_[0, layer_dims])\n",
        "    print(\"First 10 offsets:\", offs[:10])\n",
        "else:\n",
        "    print(\"Skip: pred not loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Optional: inspect test_image_paths to confirm ordering (head/tail) ---\n",
        "def head_tail(path, n=5):\n",
        "    try:\n",
        "        with open(path, 'r') as f:\n",
        "            lines = [ln.strip() for ln in f if ln.strip()]\n",
        "        print(f\"Total lines: {len(lines)}\")\n",
        "        print(\"\\nHEAD:\")\n",
        "        for ln in lines[:n]:\n",
        "            print(\"  \", ln)\n",
        "        print(\"\\nTAIL:\")\n",
        "        for ln in lines[-n:]:\n",
        "            print(\"  \", ln)\n",
        "    except FileNotFoundError:\n",
        "        print(\"File not found:\", path)\n",
        "\n",
        "head_tail(TEST_PATHS_TXT, n=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Helper: reshape one sample's flat vector to per-level maps using ref shapes ---\n",
        "def flat_to_pyramid_one(vec, ref_levels, layer_dims):\n",
        "    offs = np.cumsum(np.r_[0, layer_dims])\n",
        "    out = []\n",
        "    for i in range(len(layer_dims)):\n",
        "        sl = vec[offs[i]:offs[i+1]]\n",
        "        c, h, w = ref_levels[i]['z'].shape[1:]\n",
        "        out.append(sl.reshape(c, h, w))\n",
        "    return out\n",
        "\n",
        "if (pred is not None) and (ref is not None):\n",
        "    maps0 = flat_to_pyramid_one(pred[0], ref, layer_dims)\n",
        "    print(\"Levels:\", len(maps0))\n",
        "    print(\"Level 0 shape (C,H,W):\", maps0[0].shape)\n",
        "else:\n",
        "    print(\"Skip: need both pred and ref loaded\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}